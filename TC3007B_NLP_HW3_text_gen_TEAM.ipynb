{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Integrantes del Equipo\n",
        "\n",
        "- Jaime López Hernández A00571842\n",
        "- Ricardo Andrés Cáceres Villibord A01706972\n",
        "- Javier Suárez Durán A01707380\n",
        "- Diego Alfonso Ramírez Montes A01707596\n"
      ],
      "metadata": {
        "id": "GvA8yjuwxc01"
      },
      "id": "GvA8yjuwxc01"
    },
    {
      "cell_type": "markdown",
      "id": "037e89c8",
      "metadata": {
        "id": "037e89c8"
      },
      "source": [
        "## TC3007B\n",
        "### Text Generation\n",
        "\n",
        "<br>\n",
        "\n",
        "### Simple LSTM Text Generator using WikiText-2\n",
        "\n",
        "<br>\n",
        "\n",
        "- Objective:\n",
        "    - Gain a fundamental understanding of Long Short-Term Memory (LSTM) networks.\n",
        "    - Develop hands-on experience with sequence data processing and text generation in PyTorch. Given the simplicity of the model, amount of data, and computer resources, the text you generate will not replace ChatGPT, and results must likely will not make a lot of sense. Its only purpose is academic and to understand the text generation using RNNs.\n",
        "    - Enhance code comprehension and documentation skills by commenting on provided starter code.\n",
        "    \n",
        "<br>\n",
        "\n",
        "- Instructions:\n",
        "    - Code Understanding: Begin by thoroughly reading and understanding the code. Comment each section/block of the provided code to demonstrate your understanding. For this, you are encouraged to add cells with experiments to improve your understanding\n",
        "\n",
        "    - Model Overview: The starter code includes an LSTM model setup for sequence data processing. Familiarize yourself with the model architecture and its components. Once you are familiar with the provided model, feel free to change the model to experiment.\n",
        "\n",
        "    - Training Function: Implement a function to train the LSTM model on the WikiText-2 dataset. This function should feed the training data into the model and perform backpropagation.\n",
        "\n",
        "    - Text Generation Function: Create a function that accepts starting text (seed text) and a specified total number of words to generate. The function should use the trained model to generate a continuation of the input text.\n",
        "\n",
        "    - Code Commenting: Ensure that all the provided starter code is well-commented. Explain the purpose and functionality of each section, indicating your understanding.\n",
        "\n",
        "    - Submission: Submit your Jupyter Notebook with all sections completed and commented. Include a markdown cell with the full names of all contributing team members at the beginning of the notebook.\n",
        "    \n",
        "<br>\n",
        "\n",
        "- Evaluation Criteria:\n",
        "    - Code Commenting (60%): The clarity, accuracy, and thoroughness of comments explaining the provided code. You are suggested to use markdown cells for your explanations.\n",
        "\n",
        "    - Training Function Implementation (20%): The correct implementation of the training function, which should effectively train the model.\n",
        "\n",
        "    - Text Generation Functionality (10%): A working function is provided in comments. You are free to use it as long as you make sure to uderstand it, you may as well improve it as you see fit. The minimum expected is to provide comments for the given function.\n",
        "\n",
        "    - Conclusions (10%): Provide some final remarks specifying the differences you notice between this model and the one used  for classification tasks. Also comment on changes you made to the model, hyperparameters, and any other information you consider relevant. Also, please provide 3 examples of generated texts.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3eb4b117",
      "metadata": {
        "id": "3eb4b117"
      },
      "outputs": [],
      "source": [
        "# IMPORTAMOS Y DESCARGAMOS LAS LIBRERÍAS NECESARIAS\n",
        "\n",
        "import numpy as np\n",
        "#PyTorch libraries\n",
        "import torch\n",
        "import torchtext\n",
        "from torchtext.datasets import WikiText2\n",
        "# Dataloader library\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.utils.data.dataset import random_split\n",
        "# Libraries to prepare the data\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "# neural layers\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'portalocker>=2.0.0'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKoIpcaZ-e7_",
        "outputId": "1d608e8b-e0a9-418d-f59e-2b5446e5af4e"
      },
      "id": "sKoIpcaZ-e7_",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: portalocker>=2.0.0 in /usr/local/lib/python3.10/dist-packages (2.8.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVJ9SoAt_y6E",
        "outputId": "b3beef85-9764-493d-a7a8-b12392c20557"
      },
      "id": "vVJ9SoAt_y6E",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (0.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.31.0)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.1.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.23.5)\n",
            "Requirement already satisfied: torchdata==0.7.0 in /usr/local/lib/python3.10/dist-packages (from torchtext) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (2.1.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.7.0->torchtext) (2.0.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchtext) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchtext) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6d8ff971",
      "metadata": {
        "id": "6d8ff971"
      },
      "outputs": [],
      "source": [
        "# Verificar si CUDA está disponible\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f3288ce5",
      "metadata": {
        "id": "f3288ce5"
      },
      "outputs": [],
      "source": [
        "# Cargar datasets de WikiText-2\n",
        "train_dataset, val_dataset, test_dataset = WikiText2()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "fc4c7dbd",
      "metadata": {
        "id": "fc4c7dbd"
      },
      "outputs": [],
      "source": [
        "# Tokenizador y función para obtener tokens\n",
        "tokeniser = get_tokenizer('basic_english')\n",
        "def yield_tokens(data):\n",
        "    for text in data:\n",
        "        yield tokeniser(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "2c2cb068",
      "metadata": {
        "id": "2c2cb068"
      },
      "outputs": [],
      "source": [
        "# Construir el vocabulario\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_dataset), specials=[\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"], min_freq=1)\n",
        "# Token unknown en la posición 0\n",
        "vocab.set_default_index(vocab[\"<unk>\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "134b832b",
      "metadata": {
        "id": "134b832b"
      },
      "outputs": [],
      "source": [
        "# Longitud de la secuencia\n",
        "seq_length = 50\n",
        "\n",
        "def data_process(raw_text_iter, seq_length = 50):\n",
        "    data = [torch.tensor(vocab(tokeniser(item)), dtype=torch.long) for item in raw_text_iter]\n",
        "    data = torch.cat(tuple(filter(lambda t: t.numel() > 0, data))) #remove empty tensors\n",
        "#     target_data = torch.cat(d)\n",
        "    return (data[:-(data.size(0)%seq_length)].view(-1, seq_length),\n",
        "            data[1:-(data.size(0)%seq_length-1)].view(-1, seq_length))\n",
        "\n",
        "# # Create tensors for the training set\n",
        "x_train, y_train = data_process(train_dataset, seq_length)\n",
        "x_val, y_val = data_process(val_dataset, seq_length)\n",
        "x_test, y_test = data_process(test_dataset, seq_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "4b54c04d",
      "metadata": {
        "id": "4b54c04d"
      },
      "outputs": [],
      "source": [
        "# Crear datasets\n",
        "train_dataset = TensorDataset(x_train, y_train)\n",
        "val_dataset = TensorDataset(x_val, y_val)\n",
        "test_dataset = TensorDataset(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f4d400fb",
      "metadata": {
        "id": "f4d400fb"
      },
      "outputs": [],
      "source": [
        "# Tamaño del lote\n",
        "batch_size = 64\n",
        "\n",
        "# Cargar datasets en DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "59c63b01",
      "metadata": {
        "id": "59c63b01"
      },
      "outputs": [],
      "source": [
        "# Definir el modelo LSTM\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embed_size)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, text, hidden):\n",
        "        embeddings = self.embeddings(text)\n",
        "        output, hidden = self.lstm(embeddings, hidden)\n",
        "        decoded = self.fc(output)\n",
        "        return decoded, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "\n",
        "        return (torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device),\n",
        "                torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tamaño del Vocabulario\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# Tamaño del embedding\n",
        "emb_size = 100\n",
        "\n",
        "# Numero de neuronas\n",
        "neurons = 128\n",
        "\n",
        "# Numero de capas LSTM\n",
        "num_layers = 1\n",
        "\n",
        "model = LSTMModel(vocab_size, emb_size, neurons, num_layers)"
      ],
      "metadata": {
        "id": "r8sWJHjkHGF0"
      },
      "id": "r8sWJHjkHGF0",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "215eabb9",
      "metadata": {
        "id": "215eabb9"
      },
      "outputs": [],
      "source": [
        "# def train(model, epochs, optimiser):\n",
        "#     '''\n",
        "#     The following are possible instructions you may want to conside for this function.\n",
        "#     This is only a guide and you may change add or remove whatever you consider appropriate\n",
        "#     as long as you train your model correctly.\n",
        "#         - loop through specified epochs\n",
        "#         - loop through dataloader\n",
        "#         - don't forget to zero grad!\n",
        "#         - place data (both input and target) in device\n",
        "#         - init hidden states e.g. hidden = model.init_hidden(batch_size)\n",
        "#         - run the model\n",
        "#         - compute the cost or loss\n",
        "#         - backpropagation\n",
        "#         - Update paratemers\n",
        "#         - Include print all the information you consider helpful\n",
        "\n",
        "#     '''\n",
        "\n",
        "\n",
        "#     model = model.to(device=device)\n",
        "#     model.train()\n",
        "\n",
        "#     for epoch in range(epochs):\n",
        "\n",
        "#         for i, (data, targets) in enumerate((train_loader)):\n",
        "\n",
        "#             # TO COMPLETE\n",
        "\n",
        "# FUNCION DE ENTRENAMIENTO\n",
        "def train(model, epochs, optimiser):\n",
        "    model = model.to(device=device)\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for i, (data, targets) in enumerate(train_loader):\n",
        "            # Coloca los datos en el dispositivo\n",
        "            data, targets = data.to(device), targets.to(device)\n",
        "\n",
        "            # Inicializa los estados ocultos\n",
        "            hidden = model.init_hidden(data.size(0))\n",
        "\n",
        "            # Resetea los gradientes\n",
        "            optimiser.zero_grad()\n",
        "\n",
        "            # Pasa la entrada a través del modelo\n",
        "            output, _ = model(data, hidden)\n",
        "\n",
        "            # Calcula la pérdida\n",
        "            loss = F.cross_entropy(output.view(-1, vocab_size), targets.view(-1))\n",
        "\n",
        "            # Realiza la retropropagación y actualiza los parámetros\n",
        "            loss.backward()\n",
        "            optimiser.step()\n",
        "\n",
        "            # Imprime información cada 100 iteraciones\n",
        "            if i % 100 == 0:\n",
        "                print(f'Epoch: {epoch}, Iteration: {i}, Loss: {loss.item()}')\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "aa9c84ce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa9c84ce",
        "outputId": "4838cfc5-165f-4c75-9ca9-4fe90140216e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Iteration: 0, Loss: 10.269272804260254\n",
            "Epoch: 0, Iteration: 100, Loss: 7.0834059715271\n",
            "Epoch: 0, Iteration: 200, Loss: 7.020954608917236\n",
            "Epoch: 0, Iteration: 300, Loss: 6.919788360595703\n",
            "Epoch: 0, Iteration: 400, Loss: 6.739582061767578\n",
            "Epoch: 0, Iteration: 500, Loss: 6.636857509613037\n",
            "Epoch: 0, Iteration: 600, Loss: 6.716161727905273\n",
            "Epoch: 1, Iteration: 0, Loss: 6.465364933013916\n",
            "Epoch: 1, Iteration: 100, Loss: 6.569154262542725\n",
            "Epoch: 1, Iteration: 200, Loss: 6.519123077392578\n",
            "Epoch: 1, Iteration: 300, Loss: 6.5452446937561035\n",
            "Epoch: 1, Iteration: 400, Loss: 6.471503734588623\n",
            "Epoch: 1, Iteration: 500, Loss: 6.271101474761963\n",
            "Epoch: 1, Iteration: 600, Loss: 6.317387104034424\n",
            "Epoch: 2, Iteration: 0, Loss: 6.291142463684082\n",
            "Epoch: 2, Iteration: 100, Loss: 6.309868812561035\n",
            "Epoch: 2, Iteration: 200, Loss: 6.309752941131592\n",
            "Epoch: 2, Iteration: 300, Loss: 6.181036949157715\n",
            "Epoch: 2, Iteration: 400, Loss: 6.213590145111084\n",
            "Epoch: 2, Iteration: 500, Loss: 6.15873908996582\n",
            "Epoch: 2, Iteration: 600, Loss: 6.196441650390625\n",
            "Epoch: 3, Iteration: 0, Loss: 5.9898505210876465\n",
            "Epoch: 3, Iteration: 100, Loss: 6.0173821449279785\n",
            "Epoch: 3, Iteration: 200, Loss: 5.986142158508301\n",
            "Epoch: 3, Iteration: 300, Loss: 5.983015537261963\n",
            "Epoch: 3, Iteration: 400, Loss: 6.043515682220459\n",
            "Epoch: 3, Iteration: 500, Loss: 6.034555435180664\n",
            "Epoch: 3, Iteration: 600, Loss: 6.067319869995117\n",
            "Epoch: 4, Iteration: 0, Loss: 5.976490020751953\n",
            "Epoch: 4, Iteration: 100, Loss: 5.898909091949463\n",
            "Epoch: 4, Iteration: 200, Loss: 5.907230377197266\n",
            "Epoch: 4, Iteration: 300, Loss: 5.950991630554199\n",
            "Epoch: 4, Iteration: 400, Loss: 5.932945728302002\n",
            "Epoch: 4, Iteration: 500, Loss: 5.937144756317139\n",
            "Epoch: 4, Iteration: 600, Loss: 5.844675064086914\n"
          ]
        }
      ],
      "source": [
        "# Llamar a la función de entrenamiento\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "lr = 0.0005\n",
        "epochs = 5\n",
        "optimiser = optim.Adam(model.parameters(), lr=lr)\n",
        "train(model, epochs, optimiser)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "c8667411",
      "metadata": {
        "id": "c8667411"
      },
      "outputs": [],
      "source": [
        "# def generate_text(model, start_text, num_words, temperature=1.0):\n",
        "#     '''\n",
        "#     model.eval()\n",
        "#     words = tokeniser(start_text)\n",
        "#     hidden = model.init_hidden(1)\n",
        "#     for i in range(0, num_words):\n",
        "#         x = torch.tensor([[vocab[word] for word in words[i:]]], dtype=torch.long, device=device)\n",
        "#         y_pred, hidden = model(x, hidden)\n",
        "#         last_word_logits = y_pred[0][-1]\n",
        "#         p = (F.softmax(last_word_logits / temperature, dim=0).detach()).to(device='cpu').numpy()\n",
        "#         word_index = np.random.choice(len(last_word_logits), p=p)\n",
        "#         words.append(vocab.lookup_token(word_index))\n",
        "\n",
        "#     return ' '.join(words)\n",
        "#     '''\n",
        "\n",
        "#     pass\n",
        "\n",
        "# # Generate some text\n",
        "# print(generate_text(model, start_text=\"I like\", num_words=100))\n",
        "\n",
        "# FUNCION PARA GENERAR TEXTO\n",
        "def generate_text(model, start_text, num_words, temperature=1.0):\n",
        "    model.eval()\n",
        "    words = tokeniser(start_text)\n",
        "    hidden = model.init_hidden(1)\n",
        "\n",
        "    for i in range(0, num_words):\n",
        "        # Preparar la entrada\n",
        "        x = torch.tensor([[vocab[word] for word in words[i:]]], dtype=torch.long, device=device)\n",
        "\n",
        "        # Obtener la predicción del modelo\n",
        "        y_pred, hidden = model(x, hidden)\n",
        "\n",
        "        # Obtener las probabilidades y muestrear la siguiente palabra\n",
        "        last_word_logits = y_pred[0][-1]\n",
        "        p = (F.softmax(last_word_logits / temperature, dim=0).detach()).to(device='cpu').numpy()\n",
        "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
        "        words.append(vocab.lookup_token(word_index))\n",
        "\n",
        "    return ' '.join(words)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GUARDAR EL MODELO EN DRIVE\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Ruta en Google Drive donde deseas guardar el modelo\n",
        "ruta_guardado = '/content/drive/MyDrive/Colab Notebooks/NLP_HW3.pth'\n",
        "\n",
        "# Guardar el modelo en Google Drive\n",
        "torch.save(model.state_dict(), ruta_guardado)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FzOKWDvuLAl",
        "outputId": "68b6c0e4-dde9-4f7d-801f-a06ecad5e67f"
      },
      "id": "_FzOKWDvuLAl",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "d2884543",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2884543",
        "outputId": "312c9c99-e3d1-4f69-8a25-e4fe0e164578"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i like boston until the various women ( 2005 ft ) = = = reception = = reception = = public l rat ( 6 @ , @ . @ 3 @ 4 @ . @ . @ 200 . @ . @ 2 @ . @ @-@ . @ popularly ) i connected that programs fluorescent ( 1940 ) , <unk> , but two to drained had provided assume that omar liquor oswald . they played <unk> and <unk> or . this is true of barbados . the image at or villaret by a turned ornament with a living new york\n"
          ]
        }
      ],
      "source": [
        "# Generar texto de ejemplo\n",
        "generated_text = generate_text(model, start_text=\"I like\", num_words=100)\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cb126a2",
      "metadata": {
        "id": "1cb126a2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6de373d8",
      "metadata": {
        "id": "6de373d8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68d82438",
      "metadata": {
        "id": "68d82438"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}